"""
Test Real - Modelo de PredicciÃ³n de Rebotes NBA con Stacking Avanzado
===================================================================

Script de prueba usando el data loader real con stacking de mÃºltiples modelos
y caracterÃ­sticas de interacciÃ³n para alcanzar â‰¥97% precisiÃ³n.

Objetivo: Validar el pipeline optimizado con datos reales NBA.
"""

import pandas as pd
import numpy as np
import logging
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def main():
    """FunciÃ³n principal del test con stacking avanzado."""
    
    logger.info("ğŸ€ INICIANDO TEST REAL - STACKING AVANZADO DE REBOTES NBA")
    
    try:
        # Importar mÃ³dulos necesarios
        from src.preprocessing.data_loader import NBADataLoader
        from src.models.players.trb.features_trb import ReboundsFeatureEngineer
        from src.models.players.trb.trb_model import ReboundsPredictor
        
        # 1. CARGAR DATOS REALES
        logger.info("ğŸ“Š Cargando datos reales NBA...")
        
        # Rutas a los archivos de datos
        game_data_path = "data/players.csv"
        biometrics_path = "data/height.csv"
        teams_path = "data/teams.csv"
        
        # Inicializar data loader con rutas correctas
        data_loader = NBADataLoader(game_data_path, biometrics_path, teams_path)
        
        # Cargar datos completos
        players_df, teams_df = data_loader.load_data()
        
        # Tomar muestra de 3000 registros para prueba
        sample_size = 2000
        if len(players_df) > sample_size:
            # Muestreo estratificado por rebotes
            players_df['trb_bin'] = pd.cut(players_df['TRB'], bins=5, labels=False)
            sample_df = players_df.groupby('trb_bin', group_keys=False).apply(
                lambda x: x.sample(min(len(x), sample_size // 5), random_state=42)
            ).reset_index(drop=True)
            sample_df = sample_df.drop('trb_bin', axis=1)
        else:
            sample_df = players_df.copy()
        
        logger.info(f"   âœ… Muestra final: {len(sample_df)} registros")
        logger.info(f"   ğŸ“ˆ Jugadores Ãºnicos: {sample_df['Player'].nunique()}")
        logger.info(f"   ğŸ“… Rango de fechas: {sample_df['Date'].min()} a {sample_df['Date'].max()}")
        logger.info(f"   ğŸ¯ Rebotes - Min: {sample_df['TRB'].min()}, Max: {sample_df['TRB'].max()}, Promedio: {sample_df['TRB'].mean():.1f}")
        
        # 2. GENERAR CARACTERÃSTICAS OPTIMIZADAS CON INTERACCIONES
        logger.info("ğŸ”§ Preparando datos para generaciÃ³n de caracterÃ­sticas...")
        
        # Verificar columnas necesarias
        required_cols = ['Player', 'Date', 'Team', 'Opp', 'TRB']
        missing_cols = [col for col in required_cols if col not in sample_df.columns]
        if missing_cols:
            raise ValueError(f"Columnas faltantes: {missing_cols}")
        
        # Importar y usar feature engineer optimizado
        logger.info("âœ… MÃ³dulo de caracterÃ­sticas importado correctamente")
        feature_engineer = ReboundsFeatureEngineer()
        logger.info("ReboundsFeatureEngineer OPTIMIZADO con caracterÃ­sticas de interacciÃ³n inicializado")
        
        # Generar caracterÃ­sticas juego por juego con equipos
        logger.info("ğŸ”§ Generando caracterÃ­sticas optimizadas con interacciones...")
        X, y, feature_names = feature_engineer.generate_game_by_game_features(
            sample_df, 
            target_col='TRB',
            min_games=3,  # Reducido para tener mÃ¡s datos
            teams_df=teams_df
        )
        
        logger.info("âœ… CaracterÃ­sticas generadas con datos reales:")
        logger.info(f"   - Muestras: {len(X)}")
        logger.info(f"   - CaracterÃ­sticas: {len(feature_names)}")
        logger.info(f"   - Target promedio: {y.mean():.2f} rebotes")
        logger.info(f"   - Target rango: {y.min()}-{y.max()} rebotes")
        logger.info(f"   - Target std: {y.std():.2f}")
        
        # AnÃ¡lisis de caracterÃ­sticas por grupo
        interaction_features = [f for f in feature_names if 'x_' in f or 'interaction' in f]
        opportunity_features = [f for f in feature_names if any(x in f for x in ['missed', 'opportunity', 'mp', 'minutes'])]
        activity_features = [f for f in feature_names if any(x in f for x in ['stl', 'blk', 'activity', 'defense'])]
        team_features = [f for f in feature_names if any(x in f for x in ['team_', 'opp_', 'game_pace', 'matchup'])]
        
        logger.info("DistribuciÃ³n por grupo:")
        logger.info(f"  Interacciones: {len(interaction_features)}")
        logger.info(f"  Oportunidades: {len(opportunity_features)}")
        logger.info(f"  Actividad: {len(activity_features)}")
        logger.info(f"  Equipos: {len(team_features)}")
        
        # 3. ENTRENAR MODELO ULTRA-AVANZADO DE TERCER NIVEL
        logger.info("ğŸš€ Entrenando modelo ULTRA-AVANZADO de tercer nivel...")
        
        # Crear predictor ultra-avanzado con ensemble de tercer nivel
        predictor = ReboundsPredictor(
            use_deep_learning=True,
            aggressive_optimization=True,
            third_level_ensemble=True
        )
        
        # Entrenar modelo ultra-avanzado
        training_metrics = predictor.train(X, y, feature_names)
        
        logger.info("ğŸ† RESULTADOS DEL ENSEMBLE ULTRA-AVANZADO DE TERCER NIVEL:")
        logger.info(f"   MAE: {training_metrics['mae_mean']:.3f} Â± {training_metrics['mae_std']:.3f} rebotes")
        logger.info(f"   RÂ²: {training_metrics['r2_mean']:.3f} Â± {training_metrics['r2_std']:.3f}")
        logger.info(f"   PrecisiÃ³n Â±1 rebote: {training_metrics['accuracy_mean']:.1f}% Â± {training_metrics['accuracy_std']:.1f}%")
        logger.info(f"   PrecisiÃ³n exacta (Â±0.5): {training_metrics['exact_accuracy_mean']:.1f}% Â± {training_metrics['exact_accuracy_std']:.1f}%")
        
        # 4. VALIDACIÃ“N CRUZADA AVANZADA (ya realizada en train)
        logger.info("âœ… ValidaciÃ³n cruzada completada durante el entrenamiento")
        cv_metrics = training_metrics  # Ya son las mÃ©tricas de CV
        
        logger.info("ğŸ“Š RESULTADOS DE VALIDACIÃ“N CRUZADA:")
        logger.info(f"   MAE promedio: {cv_metrics['mae_mean']:.3f} Â± {cv_metrics['mae_std']:.3f}")
        logger.info(f"   PrecisiÃ³n promedio: {cv_metrics['accuracy_mean']:.1f}% Â± {cv_metrics['accuracy_std']:.1f}%")
        logger.info(f"   PrecisiÃ³n exacta promedio: {cv_metrics['exact_accuracy_mean']:.1f}% Â± {cv_metrics['exact_accuracy_std']:.1f}%")
        
        # 5. ANÃLISIS DE IMPORTANCIA DE CARACTERÃSTICAS (simplificado)
        logger.info("ğŸ” AnÃ¡lisis de caracterÃ­sticas completado durante el entrenamiento")
        
        # 6. EVALUACIÃ“N FINAL
        logger.info("ğŸ† EVALUACIÃ“N FINAL DEL SISTEMA:")
        
        # Calcular mÃ©tricas objetivo
        target_mae = 1.0  # MAE objetivo < 1.0 rebote
        target_accuracy_exact = 97.0  # PrecisiÃ³n exacta objetivo â‰¥ 97%
        target_accuracy_1 = 95.0  # PrecisiÃ³n Â±1 objetivo â‰¥ 95%
        
        mae_achieved = training_metrics['mae_mean'] <= target_mae
        accuracy_exact_achieved = training_metrics['exact_accuracy_mean'] >= target_accuracy_exact
        accuracy_1_achieved = training_metrics['accuracy_mean'] >= target_accuracy_1
        
        logger.info(f"   ğŸ¯ MAE < {target_mae}: {'âœ…' if mae_achieved else 'âŒ'} ({training_metrics['mae_mean']:.3f})")
        logger.info(f"   ğŸ¯ PrecisiÃ³n exacta â‰¥ {target_accuracy_exact}%: {'âœ…' if accuracy_exact_achieved else 'âŒ'} ({training_metrics['exact_accuracy_mean']:.1f}%)")
        logger.info(f"   ğŸ¯ PrecisiÃ³n Â±1 â‰¥ {target_accuracy_1}%: {'âœ…' if accuracy_1_achieved else 'âŒ'} ({training_metrics['accuracy_mean']:.1f}%)")
        
        # EvaluaciÃ³n del objetivo principal
        if accuracy_exact_achieved and mae_achieved:
            logger.info("ğŸ‰ Â¡OBJETIVO ALCANZADO! Sistema listo para producciÃ³n")
        elif training_metrics['exact_accuracy_mean'] >= 95.0:
            logger.info("ğŸ”¥ Muy cerca del objetivo - Sistema casi listo")
        elif training_metrics['accuracy_mean'] >= 90.0:
            logger.info("âš¡ Buen rendimiento - Necesita optimizaciÃ³n adicional")
        else:
            logger.info("âš ï¸  Necesita mÃ¡s optimizaciÃ³n para alcanzar â‰¥97% precisiÃ³n exacta")
        
        # 7. RECOMENDACIONES DE MEJORA
        logger.info("ğŸ’¡ RECOMENDACIONES PARA OPTIMIZACIÃ“N:")
        
        if training_metrics['mae_mean'] > target_mae:
            logger.info("   - Ajustar hiperparÃ¡metros del meta-modelo")
            logger.info("   - AÃ±adir mÃ¡s modelos base especializados")
        
        if training_metrics['exact_accuracy_mean'] < target_accuracy_exact:
            logger.info("   - Implementar ensemble de tercer nivel")
            logger.info("   - AÃ±adir caracterÃ­sticas especÃ­ficas por jugador")
            logger.info("   - Usar datos de tracking avanzado si estÃ¡n disponibles")
            logger.info("   - Optimizar thresholds de predicciÃ³n")
        
        if training_metrics['accuracy_mean'] < 90.0:
            logger.info("   - Revisar feature engineering")
            logger.info("   - Aumentar tamaÃ±o del dataset")
            logger.info("   - Implementar tÃ©cnicas de data augmentation")
        
        logger.info("âœ… TEST COMPLETADO EXITOSAMENTE")
        
        return {
            'training_metrics': training_metrics,
            'cv_metrics': cv_metrics,
            'feature_count': len(feature_names),
            'interaction_count': len(interaction_features),
            'samples': len(X),
            'target_achieved': accuracy_exact_achieved and mae_achieved
        }
        
    except Exception as e:
        logger.error(f"âŒ Error en el test: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return None

if __name__ == "__main__":
    results = main() 